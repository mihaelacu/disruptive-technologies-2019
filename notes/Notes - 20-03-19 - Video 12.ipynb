{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video 12. Linear Regression Analysis\n",
    "***\n",
    "\n",
    "- Sample venture capitalist firm\n",
    "- For simplicity it considers only a single variable (R&D) in this case to find out in which companies to invest in\n",
    "- When the sample data is plotted:\n",
    "\n",
    "![](img/200319/1.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- Companies spending more on R&D make good profit, so the venture capital firm wants to invest in them\n",
    "\n",
    "\n",
    "### Independent & Dependent Variables\n",
    "- Example: Based on the amount of rainfall, how much would be the crop yield?\n",
    "\n",
    "**INDEPENDENT VARIABLE**\n",
    "- a variable whose value does not change by the effect of other variables and is used to manipulate the dependent variable\n",
    "- often denoted as **X**\n",
    "- for our case it would be rainfall\n",
    "\n",
    "**DEPENDENT VARIABLE**\n",
    "- a variable whose value change when there is any manipulation in the values of independent variables\n",
    "- often denoted as **Y**\n",
    "- for our case it would be crop yield\n",
    "\n",
    "\n",
    "### Numerical & Categorical Values\n",
    "\n",
    "![](img/200319/2.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "\n",
    "### ML Algorithms for Linear Regression\n",
    "- LR falls in the category of Supervised ML algorithms\n",
    "- The whole group of Regression algorithms contains:\n",
    "    - Simple Linear Regression\n",
    "    - Multiple Linear Regression\n",
    "    - Polynomial Linear Regression\n",
    "    \n",
    "    \n",
    "### Applications of Linear Regression\n",
    "- Economic Growth\n",
    "    - used to determine economic growth of a country or a state in the coming quarter\n",
    "    - can also be used to predict the GDP of a country\n",
    "- Product Price\n",
    "    - can be used to predict what would be the price of a product in the future\n",
    "- Housing Sales\n",
    "    - to estimate the number of houses a builder would sell and at what price in the coming months\n",
    "- Score Prediction\n",
    "    - to predict the number of runs a player would score in the coming matches based on previous performance\n",
    "    \n",
    "    \n",
    "### Understanding Linear Regression\n",
    "- Linear Regression is a statistical model used to predict the relationship between independent and dependent variables by examining two factors:\n",
    "    - Which variables in particular are significant predictiors of the outcome variables?\n",
    "    - How significant is the Regression line to make predictions with highest possible accuracy\n",
    "    \n",
    "- The simplest form of a simple linear regression equation with one dependent and one independent variable is represented by:\n",
    "\n",
    "$$ \\large y = mx + c $$\n",
    "\n",
    "![](img/200319/3.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "Where:\n",
    "- y = dependent variable\n",
    "- x = independent variable\n",
    "- c = coefficient of the line\n",
    "- m = slope of the line\n",
    "\n",
    "$$ \\large m = \\frac{y_2 - y_1}{x_2 - x_1} $$\n",
    "\n",
    "Let's go back to the rainfall - crop yield example. If we plot rainfall on the x-axis and crop yield on the y-axis we can draw a regression line where we can predict the amount of crop yield based on the rainfall:\n",
    "\n",
    "![](img/200319/4.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "\n",
    "#### Intuition behind the Regression line\n",
    "- Lets consider a sample dataset with 5 rows and find out how to draw the regression line:\n",
    "\n",
    "![](img/200319/5.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- If we go ahead and plot those point on a graph we can see how a line would fir perfectly through the middle:\n",
    "\n",
    "![](img/200319/6.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- The next we want to know is what the *mean* is:\n",
    "    - **3** for the X variable\n",
    "    - **4** for the Y variable\n",
    "- If we plot the means on the graph it makes a nice line through the middle:\n",
    "\n",
    "![](img/200319/7.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- From that point we can calculate the relevant features in the dataset: $ X^2, Y^2 and XY $, along with their sums:\n",
    "\n",
    "![](img/200319/8.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- And we can get the formulas for $ m $ and $ c $:\n",
    "\n",
    "![](img/200319/9.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- Now we can go and find out the predicted values of Y for corresponding values of X using the linear equation where **m = 0.6** and **c = 2.2**\n",
    "- The blue points represent the **actual Y values** and the brown points represent the predicted Y values\n",
    "- The distance between the actual and predicted values are known as **residuals or errors**\n",
    "- The best fit line should have the least sum of squares of there errors also known as **e square**\n",
    "\n",
    "![](img/200319/10.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- The sum of squared errors for this regression line is 2.4\n",
    "- We check this error for each line and conclude the best fir line having the least e square value\n",
    "\n",
    "![](img/200319/11.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- We keep mobing this line through the data points to make sure the Best fir line has the least square distance between the data points and the regression line\n",
    "- There are a lots of ways to minimize the distance between the line and the data points like: Sum of Squared Errors, Sum of Absolute Errors, Root Mean Square Error...\n",
    "\n",
    "\n",
    "<br><br>\n",
    "## Multiple Linear Regression\n",
    "\n",
    "![](img/200319/12.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- Multiple variables coming in\n",
    "- Instead of $ x $ we have $ x_1, x_2, x_3 $ etc\n",
    "- Instead of having one slope, each variable has it's own slope attached to it - $ m_1, m_2, m_3 $ etc\n",
    "\n",
    "\n",
    "<br><br>\n",
    "## Multiple Linear Regression Implementation\n",
    "- Instead of looking just at R&D we'll look at multiple features:\n",
    "\n",
    "![](img/200319/13.png)\n",
    "<br>**Source:** *https://youtu.be/NUXdtN1W1FE?list=PLEiEAq2VkUULYYgj13YHUWmRePqiu8Ddy*<br>\n",
    "\n",
    "- From there we'll try to predict what the profit would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset from the video is not available online so I'll only write the code without executing it.\n",
    "\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        %matplotlib inline\n",
    "\n",
    "        companies = pd.read_csv(\"Companies.csv\")\n",
    "        X = companies.iloc[:, :-1].values\n",
    "        y = companies.iloc[:, 4].values\n",
    "        \n",
    "        companies.head()\n",
    "        \n",
    "        \n",
    "       # data visualization  - correlation matrix\n",
    "       sns.heatmap(companies.corr())\n",
    "       \n",
    "       \n",
    "       # Encoding categorical data\n",
    "           # the third column in the dataset is categorical\n",
    "           # linear regression does not know how to process categorical data\n",
    "           # we need to change values to numbers\n",
    "       from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "       labelencoder = LabelEncoder()\n",
    "       \n",
    "       # this line changes categorical values to numbers\n",
    "       X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "       \n",
    "       # One Hot Encoder\n",
    "           # makes binarization of integer categories\n",
    "           # creates a new column for every category\n",
    "               # puts 1 if is in category\n",
    "               # 0 if isn't\n",
    "       onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "       \n",
    "       # preparates the data to be a row of numbers\n",
    "       X = onehotencoder.fit_transform(X).toarray()\n",
    "       \n",
    "       \n",
    "       # Avoiding dummy variable trap:\n",
    "       X = X[:, 1:]\n",
    "       \n",
    "       \n",
    "       \n",
    "       # Splitting the data into train and test set\n",
    "       from sklearn.model selection import train_test_split\n",
    "       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "       \n",
    "       \n",
    "       \n",
    "       # Fitting Multiple Linear Regression Model to Training set:\n",
    "       from sklearn.linear_model import LinearRegression\n",
    "       model_fit = LinearRegression()\n",
    "       model_fit.fit(X_train, y_train)\n",
    "       \n",
    "       \n",
    "       \n",
    "       # Making predictions\n",
    "       y_pred = model_fit.predict(X_test)\n",
    "       \n",
    "       \n",
    "       \n",
    "       # Calculating coefficients and the intercept\n",
    "       print(model_fit.coef_)\n",
    "       print(model_fit.intercept_)\n",
    "       \n",
    "       \n",
    "       \n",
    "       # Calculating the R squared value\n",
    "           # tells us how good the prediction is\n",
    "           # not a percentage, but should be above 0.9\n",
    "       from sklearn.metrics import r2_score\n",
    "       r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
